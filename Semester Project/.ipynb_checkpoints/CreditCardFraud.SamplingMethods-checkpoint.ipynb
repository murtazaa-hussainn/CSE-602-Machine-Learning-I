{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Semester Project\n",
    "## Murtaza Hussain (29449) and Muhammad Asad ur Rehman (29456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance Problem\n",
    "\n",
    "The below code solves the prevalent problem of imbalanced dataset, where one class dominates the dataset as compared to the other. Such is the case for the following dataset for Credit Card Transactions to detect Fraudulent Transactions. We will evaluate the following methods to resolve Class Imbalance:\n",
    "1. Random Under Sampling\n",
    "2. Algorithmic Methods (Using Random Forest as well as modifying Class Weights)\n",
    "3. Anomaly Detection Method\n",
    "\n",
    "For the following Dataset, we will use the following 5 Algorithms to draw a comparision between different methods:\n",
    "1. Logistic Regression\n",
    "2. K-Nearest Neighbors (KNN)\n",
    "3. Random Forest\n",
    "4. Support Vector Machines (SVM)\n",
    "5. Naive Bayes (Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import make_scorer, recall_score, precision_score\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader loads data from CSV Files\n",
    "def load_dataset():\n",
    "    dataset = pd.read_csv(\"./Source.CreditCardFraud.csv\")\n",
    "    return dataset\n",
    "\n",
    "# df = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performs a missing value analysis on each column of the dataset, helps you decide on what to do in cleaning process\n",
    "def null_check(df):\n",
    "    null_columns = []\n",
    "    for column in df.columns:\n",
    "        print(\"Column Name:\", column)\n",
    "        print(\"Column DataType:\", df[column].dtype)\n",
    "        if df[column].dtype != 'float64' and df[column].dtype != 'int64':\n",
    "            print(\"Column unique values:\", df[column].unique())\n",
    "        print(\"Column has null:\", df[column].isnull().any())\n",
    "\n",
    "        \n",
    "        if df[column].isnull().any() == True:\n",
    "            print(\"Column Null Count:\", df[column].isnull().sum())\n",
    "            null_columns.append(column)\n",
    "        print(\"\\n\")\n",
    "    return null_columns\n",
    "\n",
    "# null_check(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function drops any null columns and missing values\n",
    "# This is where you decide whether to remove NULL rows (which will reduce the size of Dataset) or remove NULL columns entirely. You can also choose a combination of both.\n",
    "def clean_data(df, drop_columns, missing_value = False):\n",
    "    # Remove unnecessary columns\n",
    "    df.drop(drop_columns, axis=1, inplace=True)\n",
    "    # Drop rows with any missing values\n",
    "    if missing_value == False:\n",
    "        df.dropna(inplace=True)\n",
    "    else:\n",
    "        df.fillna(missing_value, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints a summary of class instances and distribution\n",
    "def data_summary(df, target=None):\n",
    "    if isinstance(df, pd.DataFrame) and target!=None:\n",
    "        a = df[target].value_counts()\n",
    "    else:\n",
    "        a = df.value_counts()\n",
    "    class0 = format(100 * a[0]/sum(a), \".2f\")\n",
    "    class1 = format(100 * a[1]/sum(a), \".2f\")\n",
    "\n",
    "    meta = pd.DataFrame([{ \"%\": class0, \"count\": a[0]},\n",
    "                         { \"%\": class1, \"count\": a[1]}])\n",
    "    print(\"\\nClass Distribution:\\n\", meta, \"\\n\")\n",
    "\n",
    "# data_summary(df,'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms categorical and numberical data into numerical data\n",
    "def transform_data(df):\n",
    "    # Encode categorical variables\n",
    "    label_encoder = LabelEncoder()\n",
    "    print(\"Categorical columns:\", df.select_dtypes(include=['object', 'int64']).columns)\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "    \n",
    "    # Standardize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    print(\"Numerical columns:\", df.select_dtypes(include=['float64']).columns)\n",
    "    numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    if len(numerical_cols) > 0:\n",
    "        df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "    return df\n",
    "\n",
    "# df['Class'] = df['Class'].astype(str)\n",
    "# df = transform_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs Baseline Model for All 5 Algorithms\n",
    "def BaselineRunAll(df, target_name, k=10):\n",
    "\n",
    "    # Separate features and targets\n",
    "    X = df.drop(target_name, axis=1)\n",
    "    y = df[target_name]\n",
    "    results = []\n",
    "\n",
    "    print(\"Class Distribution for Baseline Run:\")\n",
    "    data_summary(y)\n",
    "\n",
    "    # Initialize the classifiers\n",
    "    lr_classifier = LogisticRegression(max_iter=1000)\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "    knn_classifier = KNeighborsClassifier()\n",
    "    svm_classifier = SVC(probability=True)\n",
    "    nb_classifier = GaussianNB()\n",
    "    \n",
    "\n",
    "    # Initialize k-fold cross-validation where folds = 10\n",
    "    k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)     # The reasoning behind k = 10 is so as to strike a balance between test and train samples of minority class\n",
    "\n",
    "    # Define a recall and precision scorer specifically focusing on the minority class\n",
    "    recall_precision_scorer = {'recall': make_scorer(recall_score, pos_label=1), # As the majority class has 99.81% presence, accuracy cannot be used as a metric to evaluate performance\n",
    "                               'precision': make_scorer(precision_score, pos_label=1)}\n",
    "    \n",
    "    classifiers = {\n",
    "        'Logistic Regression': lr_classifier,\n",
    "        'Random Forest': rf_classifier,\n",
    "        'K-Nearest Neighbours': knn_classifier,\n",
    "        'Support Vector Machines': svm_classifier,\n",
    "        'Naive Bayes': nb_classifier\n",
    "    }\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        scores = cross_validate(clf, X, y, cv=k_fold, scoring=recall_precision_scorer)\n",
    "        print(f\"{clf_name} Model Training Completed\")\n",
    "        mean_recall = scores['test_recall'].mean()\n",
    "        mean_precision = scores['test_precision'].mean()\n",
    "\n",
    "        results.append({\n",
    "            'Method': 'Baseline',\n",
    "            'Classifier': clf_name,\n",
    "            'Class 1 Recall': mean_recall,\n",
    "            'Class 1 Precision': mean_precision\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# results = BaselineRunAll(df, 'Class')\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs Undersampling of Majority Class followed by Oversampling of Minority class using SMOTE and tests on all 5 Algorithms\n",
    "def RandomSamplingSMOTE(df, target_name, k=10):\n",
    "\n",
    "    # Separate features and targets\n",
    "    X = df.drop(target_name, axis=1)\n",
    "    y = df[target_name]\n",
    "    results = []\n",
    "\n",
    "    # Undersample Majority Class\n",
    "    rus = RandomUnderSampler(sampling_strategy={0: 50000, 1: 223}, random_state=42)\n",
    "    X, y = rus.fit_resample(X, y)\n",
    "    \n",
    "    print(\"Class Distribution after Undersampling Majority Class:\")\n",
    "    data_summary(y)\n",
    "\n",
    "    # Oversample using SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X, y = smote.fit_resample(X, y)\n",
    "    \n",
    "    print(\"Class Distribution after Oversampling Minority Class using SMOTE:\")\n",
    "    data_summary(y)\n",
    "\n",
    "    # Initialize the classifiers\n",
    "    lr_classifier = LogisticRegression(max_iter=1000)\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "    knn_classifier = KNeighborsClassifier()\n",
    "    svm_classifier = SVC(probability=True)\n",
    "    nb_classifier = GaussianNB()\n",
    "\n",
    "    # Initialize k-fold cross-validation where folds = 10\n",
    "    k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Define a recall and precision scorer specifically focusing on the minority class\n",
    "    recall_precision_scorer = {'recall': make_scorer(recall_score, pos_label=1), \n",
    "                               'precision': make_scorer(precision_score, pos_label=1)}\n",
    "\n",
    "    classifiers = {\n",
    "        'Logistic Regression': lr_classifier,\n",
    "        'Random Forest': rf_classifier,\n",
    "        'K-Nearest Neighbours': knn_classifier,\n",
    "        'Support Vector Machines': svm_classifier,\n",
    "        'Naive Bayes': nb_classifier\n",
    "    }\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        scores = cross_validate(clf, X, y, cv=k_fold, scoring=recall_precision_scorer)\n",
    "        print(f\"{clf_name} Model Training Completed\")\n",
    "        mean_recall = scores['test_recall'].mean()\n",
    "        mean_precision = scores['test_precision'].mean()\n",
    "\n",
    "        results.append({\n",
    "            'Method': 'Undersampling + SMOTE',\n",
    "            'Classifier': clf_name,\n",
    "            'Class 1 Recall': mean_recall,\n",
    "            'Class 1 Precision': mean_precision\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# results = RandomSamplingSMOTE(df, 'Class')\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs Undersampling of Majority Class followed by Oversampling of Minority class using ADASYN and tests on all 5 Algorithms\n",
    "def RandomSamplingADASYN(df, target_name, k=10):\n",
    "\n",
    "    # Separate features and targets\n",
    "    X = df.drop(target_name, axis=1)\n",
    "    y = df[target_name]\n",
    "    results = []\n",
    "\n",
    "    # Undersample Majority Class\n",
    "    rus = RandomUnderSampler(sampling_strategy={0: 50000, 1: 223}, random_state=42)\n",
    "    X, y = rus.fit_resample(X, y)\n",
    "    \n",
    "    print(\"Class Distribution after Undersampling Majority Class:\")\n",
    "    data_summary(y)\n",
    "\n",
    "    # Oversample using ADASYN\n",
    "    adasyn = ADASYN(random_state=42)\n",
    "    X, y = adasyn.fit_resample(X, y)\n",
    "    \n",
    "    print(\"Class Distribution after Oversampling Minority Class using ADASYN:\")\n",
    "    data_summary(y)\n",
    "\n",
    "    # Initialize the classifiers\n",
    "    lr_classifier = LogisticRegression(max_iter=1000)\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "    knn_classifier = KNeighborsClassifier()\n",
    "    svm_classifier = SVC(probability=True)\n",
    "    nb_classifier = GaussianNB()\n",
    "\n",
    "    # Initialize k-fold cross-validation where folds = 10\n",
    "    k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Define a recall and precision scorer specifically focusing on the minority class\n",
    "    recall_precision_scorer = {'recall': make_scorer(recall_score, pos_label=1), \n",
    "                               'precision': make_scorer(precision_score, pos_label=1)}\n",
    "\n",
    "    classifiers = {\n",
    "        'Logistic Regression': lr_classifier,\n",
    "        'Random Forest': rf_classifier,\n",
    "        'K-Nearest Neighbours': knn_classifier,\n",
    "        'Support Vector Machines': svm_classifier,\n",
    "        'Naive Bayes': nb_classifier\n",
    "    }\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        scores = cross_validate(clf, X, y, cv=k_fold, scoring=recall_precision_scorer)\n",
    "        print(f\"{clf_name} Model Training Completed\")\n",
    "        mean_recall = scores['test_recall'].mean()\n",
    "        mean_precision = scores['test_precision'].mean()\n",
    "\n",
    "        results.append({\n",
    "            'Method': 'Undersampling + ADASYN',\n",
    "            'Classifier': clf_name,\n",
    "            'Class 1 Recall': mean_recall,\n",
    "            'Class 1 Precision': mean_precision\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# results = RandomSamplingADASYN(df, 'Class')\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Model vs Recall graph for Classification Dataset for Each Method\n",
    "def plot_model_recall_graph(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plotting lines for each Method\n",
    "    sns.lineplot(data=df, x='Classifier', y='Class 1 Recall', hue='Method', marker='o')\n",
    "\n",
    "    plt.title('Classifier vs Recall')\n",
    "    plt.xlabel('Classifier')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend(title='Method')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Model vs Precision graph for Classification Dataset for Each Method\n",
    "def plot_model_precision_graph(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plotting lines for each Method\n",
    "    sns.lineplot(data=df, x='Classifier', y='Class 1 Precision', hue='Method', marker='o')\n",
    "\n",
    "    plt.title('Classifier vs Precision')\n",
    "    plt.xlabel('Classifier')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend(title='Method')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_workflow():\n",
    "    # Load Dataset\n",
    "    df = load_dataset()\n",
    "    # No need for Data Cleaning and EDA as Data is already clean\n",
    "    # Evaluate Class Distribution of the cleaned Dataset\n",
    "    data_summary(df,'Class')\n",
    "    # Transform and Encode Data\n",
    "    df['Class'] = df['Class'].astype(str)\n",
    "    df = transform_data(df)\n",
    "    # Run Baseline Models using k = 10\n",
    "    baseline_results = BaselineRunAll(df, 'Class')\n",
    "    # Evaluate Models using SMOTE Oversampling Technique\n",
    "    smote_results = RandomSamplingSMOTE(df, 'Class')\n",
    "    # Evaluate Models using ADASYN Oversampling Technique\n",
    "    adasyn_results = RandomSamplingADASYN(df, 'Class')\n",
    "    # Concatenate the results\n",
    "    results_df = pd.concat([baseline_results, smote_results, adasyn_results])\n",
    "    # Print results\n",
    "    print(results_df)\n",
    "    results_df.to_csv('SamplingMethodsResults.csv', index=False)\n",
    "    # Plot a Classifier vs Recall Graph -> To evaluate how well the model is performing to detect the fraudulent transactions (minority class)\n",
    "    plot_model_recall_graph(results_df)\n",
    "    # Plot a Classifier vs Precision Graph -> To evaluate how precise the model is to detect the minority class (can be used as a secondary metric for evaluation)\n",
    "    plot_model_precision_graph(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the pipeline was not running in one go, we had to split it into smaller parts\n",
    "# master_workflow() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broken down pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "        %  count\n",
      "0  99.78  99776\n",
      "1   0.22    223 \n",
      "\n",
      "Categorical columns: Index(['Time', 'Class'], dtype='object')\n",
      "Numerical columns: Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
      "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
      "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df = load_dataset()\n",
    "# No need for Data Cleaning and EDA as Data is already clean\n",
    "# Evaluate Class Distribution of the cleaned Dataset\n",
    "data_summary(df,'Class')\n",
    "# Transform and Encode Data\n",
    "df['Class'] = df['Class'].astype(str)\n",
    "df = transform_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution for Baseline Run:\n",
      "\n",
      "Class Distribution:\n",
      "        %  count\n",
      "0  99.78  99776\n",
      "1   0.22    223 \n",
      "\n",
      "Logistic Regression Model Training Completed\n",
      "Random Forest Model Training Completed\n",
      "K-Nearest Neighbours Model Training Completed\n"
     ]
    }
   ],
   "source": [
    "# Run Baseline Models using k = 10\n",
    "baseline_results = BaselineRunAll(df, 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models using SMOTE Oversampling Technique\n",
    "smote_results = RandomSamplingSMOTE(df, 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models using ADASYN Oversampling Technique\n",
    "adasyn_results = RandomSamplingADASYN(df, 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the results\n",
    "results_df = pd.concat([baseline_results, smote_results, adasyn_results])\n",
    "# Print results\n",
    "print(results_df)\n",
    "results_df.to_csv('SamplingMethodsResults.csv', index=False)\n",
    "# Plot a Classifier vs Recall Graph -> To evaluate how well the model is performing to detect the fraudulent transactions (minority class)\n",
    "plot_model_recall_graph(results_df)\n",
    "# Plot a Classifier vs Precision Graph -> To evaluate how precise the model is to detect the minority class (can be used as a secondary metric for evaluation)\n",
    "plot_model_precision_graph(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
