{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Semester Project\n",
    "## Murtaza Hussain (29449) and Muhammad Asad ur Rehman (29456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance Problem\n",
    "\n",
    "The below code solves the prevalent problem of imbalanced dataset, where one class dominates the dataset as compared to the other. Such is the case for the following dataset for Credit Card Transactions to detect Fraudulent Transactions. We will evaluate the following methods to resolve Class Imbalance:\n",
    "1. Random Under Sampling\n",
    "2. Algorithmic Methods (Using Random Forest as well as modifying Class Weights)\n",
    "3. Anomaly Detection Method\n",
    "\n",
    "For the following Dataset, we will use the following 5 Algorithms to draw a comparision between different methods:\n",
    "1. Logistic Regression\n",
    "2. K-Nearest Neighbors (KNN)\n",
    "3. Random Forest\n",
    "4. Support Vector Machines (SVM)\n",
    "5. Naive Bayes (Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import precision_recall_curve, make_scorer, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, OneClassSVM\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader loads data from CSV Files\n",
    "def load_dataset():\n",
    "    dataset = pd.read_csv(\"./Source.CreditCardFraud.csv\")\n",
    "    return dataset\n",
    "\n",
    "df = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performs a missing value analysis on each column of the dataset, helps you decide on what to do in cleaning process\n",
    "def null_check(df):\n",
    "    null_columns = []\n",
    "    for column in df.columns:\n",
    "        print(\"Column Name:\", column)\n",
    "        print(\"Column DataType:\", df[column].dtype)\n",
    "        if df[column].dtype != 'float64' and df[column].dtype != 'int64':\n",
    "            print(\"Column unique values:\", df[column].unique())\n",
    "        print(\"Column has null:\", df[column].isnull().any())\n",
    "\n",
    "        \n",
    "        if df[column].isnull().any() == True:\n",
    "            print(\"Column Null Count:\", df[column].isnull().sum())\n",
    "            null_columns.append(column)\n",
    "        print(\"\\n\")\n",
    "    return null_columns\n",
    "\n",
    "# null_check(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function drops any null columns and missing values\n",
    "# This is where you decide whether to remove NULL rows (which will reduce the size of Dataset) or remove NULL columns entirely. You can also choose a combination of both.\n",
    "def clean_data(df, drop_columns, missing_value = False):\n",
    "    # Remove unnecessary columns\n",
    "    df.drop(drop_columns, axis=1, inplace=True)\n",
    "    # Drop rows with any missing values\n",
    "    if missing_value == False:\n",
    "        df.dropna(inplace=True)\n",
    "    else:\n",
    "        df.fillna(missing_value, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "        %  count\n",
      "0  99.78  99776\n",
      "1   0.22    223 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prints a summary of class instances and distribution\n",
    "def data_summary(df, target=None):\n",
    "    if isinstance(df, pd.DataFrame) and target!=None:\n",
    "        a = df[target].value_counts()\n",
    "    else:\n",
    "        a = df.value_counts()\n",
    "    class0 = format(100 * a[0]/sum(a), \".2f\")\n",
    "    class1 = format(100 * a[1]/sum(a), \".2f\")\n",
    "\n",
    "    meta = pd.DataFrame([{ \"%\": class0, \"count\": a[0]},\n",
    "                         { \"%\": class1, \"count\": a[1]}])\n",
    "    print(\"\\nClass Distribution:\\n\", meta, \"\\n\")\n",
    "\n",
    "data_summary(df,'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Index(['Time', 'Class'], dtype='object')\n",
      "Numerical columns: Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
      "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
      "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Transforms categorical and numberical data into numerical data\n",
    "def transform_data(df):\n",
    "    # Encode categorical variables\n",
    "    label_encoder = LabelEncoder()\n",
    "    print(\"Categorical columns:\", df.select_dtypes(include=['object', 'int64']).columns)\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "    \n",
    "    # Standardize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    print(\"Numerical columns:\", df.select_dtypes(include=['float64']).columns)\n",
    "    numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    if len(numerical_cols) > 0:\n",
    "        df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "    return df\n",
    "\n",
    "df['Class'] = df['Class'].astype(str)\n",
    "df = transform_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs Baseline Model for All 5 Algorithms\n",
    "def BaselineRunAll(df, target_name, k=10):\n",
    "\n",
    "    # Separate features and targets\n",
    "    X = df.drop(target_name, axis=1)\n",
    "    y = df[target_name]\n",
    "    results = []\n",
    "\n",
    "    print(\"Class Distribution for Baseline Run:\")\n",
    "    data_summary(y)\n",
    "\n",
    "    # Initialize the classifiers\n",
    "    lr_classifier = LogisticRegression(max_iter=1000)\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "    knn_classifier = KNeighborsClassifier()\n",
    "    svm_classifier = SVC(probability=True)\n",
    "    nb_classifier = GaussianNB()\n",
    "    \n",
    "\n",
    "    # Initialize k-fold cross-validation where folds = 10\n",
    "    k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)     # The reasoning behind k = 10 is so as to strike a balance between test and train samples of minority class\n",
    "\n",
    "    # Define a recall and precision scorer specifically focusing on the minority class\n",
    "    recall_precision_scorer = {'recall': make_scorer(recall_score, pos_label=1), # As the majority class has 99.81% presence, accuracy cannot be used as a metric to evaluate performance\n",
    "                               'precision': make_scorer(precision_score, pos_label=1)}\n",
    "    \n",
    "    classifiers = {\n",
    "        'Logistic Regression': lr_classifier,\n",
    "        'Random Forest': rf_classifier,\n",
    "        'K-Nearest Neighbours': knn_classifier,\n",
    "        'Support Vector Machines': svm_classifier,\n",
    "        'Naive Bayes': nb_classifier\n",
    "    }\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        scores = cross_validate(clf, X, y, cv=k_fold, scoring=recall_precision_scorer)\n",
    "        print(f\"{clf_name} Model Training Completed\")\n",
    "        mean_recall = scores['test_recall'].mean()\n",
    "        mean_precision = scores['test_precision'].mean()\n",
    "\n",
    "        results.append({\n",
    "            'Method': 'Baseline',\n",
    "            'Classifier': clf_name,\n",
    "            'Class 1 Recall': mean_recall,\n",
    "            'Class 1 Precision': mean_precision\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# results = BaselineRunAll(df, 'Class')\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution for One Class Learning (Majority Class):\n",
      "\n",
      "Class Distribution:\n",
      "        %  count\n",
      "0  99.78  99776\n",
      "1   0.22    223 \n",
      "\n",
      "                Classifier  Class 1 Recall  Class 1 Precision\n",
      "0      Logistic Regression          0.8259             0.9432\n",
      "1            Random Forest          0.8507             1.0000\n",
      "2     K-Nearest Neighbours          0.4776             1.0000\n",
      "3  Support Vector Machines          0.8856             0.9674\n",
      "4              Naive Bayes          0.8856             0.9834\n"
     ]
    }
   ],
   "source": [
    "# Performs One Class Learning (Majority Class) on all 5 Algorithms\n",
    "def OneClassLearning(df, target_name, k=10):\n",
    "\n",
    "    # Separate features and targets\n",
    "    X = df.drop(target_name, axis=1)\n",
    "    y = df[target_name]\n",
    "    results = []\n",
    "\n",
    "    # Splitting Data into Majority and Minority Classes\n",
    "    X_majority = X[y == 0]  # Features for the majority class\n",
    "    X_minority = X[y == 1]  # Features for the minority class\n",
    "\n",
    "    X_train_minority, X_test_minority = train_test_split(X_minority, test_size=0.9, random_state=42)\n",
    "    X_train_majority, X_test_majority = train_test_split(X_majority, test_size=len(X_test_minority), random_state=42)\n",
    "\n",
    "    # Adjusting test and train samples\n",
    "    X_train = np.vstack([X_train_majority, X_train_minority])  # Optionally add some X_train_minority\n",
    "    X_test = np.vstack([X_test_majority, X_test_minority])\n",
    "    y_train = np.array([0]*len(X_train_majority) + [1]*len(X_train_minority))  # + Optional minority class labels\n",
    "    y_test = np.array([0]*len(X_test_majority) + [1]*len(X_test_minority))\n",
    "\n",
    "    print(\"Class Distribution for One Class Learning (Majority Class):\")\n",
    "    data_summary(y)\n",
    "\n",
    "    # Initialize the classifiers\n",
    "    lr_classifier = LogisticRegression(max_iter=1000)\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "    knn_classifier = KNeighborsClassifier()\n",
    "    svm_classifier = SVC(probability=True)\n",
    "    nb_classifier = GaussianNB()\n",
    "\n",
    "    classifiers = {\n",
    "        'Logistic Regression': lr_classifier,\n",
    "        'Random Forest': rf_classifier,\n",
    "        'K-Nearest Neighbours': knn_classifier,\n",
    "        'Support Vector Machines': svm_classifier,\n",
    "        'Naive Bayes': nb_classifier\n",
    "    }\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(X_train, y_train)  # Train on majority class, with some minority examples\n",
    "        \n",
    "        # Evaluate the model\n",
    "        predictions = clf.predict(X_test)\n",
    "        # Convert probabilities to binary output based on a chosen threshold\n",
    "        probabilities = clf.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_test, probabilities)\n",
    "        # Calculate F1 scores for each threshold\n",
    "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "        # Find the threshold that maximizes the F1 score\n",
    "        optimal_idx = np.argmax(f1_scores)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "        optimal_precision = precisions[optimal_idx]\n",
    "        optimal_recall = recalls[optimal_idx]\n",
    "        # print(\"\\nClassifier: \", clf)\n",
    "        # print(\"Optimal Threshold: \", optimal_threshold)\n",
    "        # print(\"Optimal Precision: \", optimal_precision)\n",
    "        # print(\"Optimal Recall: \", optimal_recall)\n",
    "\n",
    "        threshold = optimal_threshold  # Adjust based on validation data\n",
    "        predictions = (probabilities > threshold).astype(int)\n",
    "\n",
    "\n",
    "        results.append({\n",
    "            'Classifier': clf_name,\n",
    "            'Class 1 Recall': recall_score(y_test, predictions, pos_label=1),\n",
    "            'Class 1 Precision': precision_score(y_test, predictions, pos_label=1)\n",
    "        })\n",
    "        # print(results)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "results = OneClassLearning(df, 'Class')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Usage:\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mOneClassLearning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_df)\n",
      "Cell \u001b[1;32mIn[8], line 36\u001b[0m, in \u001b[0;36mOneClassLearning\u001b[1;34m(df, target_name, k)\u001b[0m\n\u001b[0;32m     34\u001b[0m     clf\u001b[38;5;241m.\u001b[39mfit(X_train_majority)  \u001b[38;5;66;03m# One-Class SVM is trained only on the majority class\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 36\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_majority\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train_majority\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Other models need labels\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Predicting and scoring\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(clf, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecision_function\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1181\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1186\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1187\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1188\u001b[0m     )\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1191\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score, precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "def OneClassLearning(df, target_name, k=10):\n",
    "    # Separate features and targets\n",
    "    X = df.drop(target_name, axis=1)\n",
    "    y = df[target_name]\n",
    "\n",
    "    # Split data into Majority (normal) and Minority (anomalies)\n",
    "    X_majority = X[y == 0]\n",
    "    X_minority = X[y == 1]\n",
    "\n",
    "    # Split majority data for training, test data includes both classes\n",
    "    X_train_majority, X_test_majority = train_test_split(X_majority, test_size=0.2, random_state=42)\n",
    "    _, X_test_minority = train_test_split(X_minority, test_size=0.9, random_state=42)\n",
    "\n",
    "    # Form the test set\n",
    "    X_test = np.vstack([X_test_majority, X_test_minority])\n",
    "    y_test = np.array([0]*len(X_test_majority) + [1]*len(X_test_minority))\n",
    "\n",
    "    # Initialize the classifiers\n",
    "    classifiers = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'K-Nearest Neighbours': KNeighborsClassifier(),\n",
    "        'Support Vector Machines': OneClassSVM(kernel='rbf', gamma='auto'),\n",
    "        'Naive Bayes': GaussianNB()\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        if clf_name == 'Support Vector Machines':\n",
    "            clf.fit(X_train_majority)  # One-Class SVM is trained only on the majority class\n",
    "        else:\n",
    "            clf.fit(X_train_majority, np.zeros(len(X_train_majority)))  # Other models need labels\n",
    "        \n",
    "        # Predicting and scoring\n",
    "        if hasattr(clf, 'decision_function'):\n",
    "            scores = clf.decision_function(X_test)\n",
    "        elif hasattr(clf, 'predict_proba'):\n",
    "            scores = clf.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            scores = clf.predict(X_test)\n",
    "        \n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, scores)\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "        optimal_idx = np.argmax(f1_scores)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "        predictions = scores > optimal_threshold\n",
    "        results.append({\n",
    "            'Classifier': clf_name,\n",
    "            'Class 1 Recall': recall_score(y_test, predictions, pos_label=1),\n",
    "            'Class 1 Precision': precision_score(y_test, predictions, pos_label=1),\n",
    "            'Optimal Threshold': optimal_threshold\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Usage:\n",
    "results_df = OneClassLearning(df, 'Class')\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs One Class Learning (Majority Class) using special methods\n",
    "def OneClassLearningSpecialMethods(df, target_name, k=10):\n",
    "\n",
    "    # Separate features and targets\n",
    "    X = df.drop(target_name, axis=1)\n",
    "    y = df[target_name]\n",
    "    results = []\n",
    "\n",
    "    print(\"Class Distribution for One Class Learning Special Methods:\")\n",
    "    data_summary(y)\n",
    "\n",
    "    # Initialize the classifiers\n",
    "#    lr_classifier = LogisticRegression(max_iter=1000) # Has no such implementation\n",
    "#    rf_classifier = RandomForestClassifier() # Has no such implementation\n",
    "    knn_classifier = LocalOutlierFactor(novelty=True) # A special implementation of KNN for One Class Learning\n",
    "    svm_classifier = OneClassSVM(kernel='rbf', gamma='auto') # A special implementation of SVM for One Class Learning\n",
    "#    nb_classifier = GaussianNB() # Has no such implementation\n",
    "\n",
    "    # Initialize k-fold cross-validation where folds = 10\n",
    "    k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Define a recall and precision scorer specifically focusing on the minority class\n",
    "    recall_precision_scorer = {'recall': make_scorer(recall_score, pos_label=1), \n",
    "                               'precision': make_scorer(precision_score, pos_label=1)}\n",
    "\n",
    "    classifiers = {\n",
    "        # 'Logistic Regression': lr_classifier,\n",
    "        # 'Random Forest': rf_classifier,\n",
    "        'K-Nearest Neighbours': knn_classifier,\n",
    "        'Support Vector Machines': svm_classifier,\n",
    "        # 'Naive Bayes': nb_classifier\n",
    "    }\n",
    "\n",
    "    # Train on majority class only\n",
    "    majority_class = (y == 0)\n",
    "    X_majority = X[majority_class]\n",
    "    y_majority = y[majority_class]\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        scores = cross_validate(clf, X_majority, y_majority, cv=k_fold, scoring=recall_precision_scorer, return_train_score=False)\n",
    "        print(f\"{clf_name} Model Training Completed\")\n",
    "        mean_recall = scores['test_recall'].mean()\n",
    "        mean_precision = scores['test_precision'].mean()\n",
    "\n",
    "        results.append({\n",
    "            'Method': 'Undersampling + SMOTE',\n",
    "            'Classifier': clf_name,\n",
    "            'Class 1 Recall': mean_recall,\n",
    "            'Class 1 Precision': mean_precision\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# results = RandomSamplingSMOTE(df, 'Class')\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Model vs Recall graph for Classification Dataset for Each Method\n",
    "def plot_model_recall_graph(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plotting lines for each Method\n",
    "    sns.lineplot(data=df, x='Classifier', y='Class 1 Recall', hue='Method', marker='o')\n",
    "\n",
    "    plt.title('Classifier vs Recall')\n",
    "    plt.xlabel('Classifier')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend(title='Method')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Model vs Precision graph for Classification Dataset for Each Method\n",
    "def plot_model_precision_graph(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plotting lines for each Method\n",
    "    sns.lineplot(data=df, x='Classifier', y='Class 1 Precision', hue='Method', marker='o')\n",
    "\n",
    "    plt.title('Classifier vs Precision')\n",
    "    plt.xlabel('Classifier')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend(title='Method')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_workflow():\n",
    "    # Load Dataset\n",
    "    df = load_dataset()\n",
    "    # No need for Data Cleaning and EDA as Data is already clean\n",
    "    # Evaluate Class Distribution of the cleaned Dataset\n",
    "    data_summary(df,'Class')\n",
    "    # Transform and Encode Data\n",
    "    df['Class'] = df['Class'].astype(str)\n",
    "    df = transform_data(df)\n",
    "    # Run Baseline Models using k = 10\n",
    "    baseline_results = BaselineRunAll(df, 'Class')\n",
    "    # Evaluate Models using SMOTE Oversampling Technique\n",
    "    smote_results = RandomSamplingSMOTE(df, 'Class')\n",
    "    # Evaluate Models using ADASYN Oversampling Technique\n",
    "    adasyn_results = RandomSamplingADASYN(df, 'Class')\n",
    "    # Concatenate the results\n",
    "    results_df = pd.concat([baseline_results, smote_results, adasyn_results])\n",
    "    # Print results\n",
    "    print(results_df)\n",
    "    results_df.to_csv('Results/CreditCardFraud.OneClassLearningResults.csv', index=False)\n",
    "    # Plot a Classifier vs Recall Graph -> To evaluate how well the model is performing to detect the fraudulent transactions (minority class)\n",
    "    plot_model_recall_graph(results_df)\n",
    "    # Plot a Classifier vs Precision Graph -> To evaluate how precise the model is to detect the minority class (can be used as a secondary metric for evaluation)\n",
    "    plot_model_precision_graph(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the pipeline was not running in one go, we had to split it into smaller parts\n",
    "# master_workflow() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broken down pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = load_dataset()\n",
    "# No need for Data Cleaning and EDA as Data is already clean\n",
    "# Evaluate Class Distribution of the cleaned Dataset\n",
    "data_summary(df,'Class')\n",
    "# Transform and Encode Data\n",
    "df['Class'] = df['Class'].astype(str)\n",
    "df = transform_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Baseline Models using k = 10\n",
    "baseline_results = BaselineRunAll(df, 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models using SMOTE Oversampling Technique\n",
    "one_class_results = OneClassLearning(df, 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models using ADASYN Oversampling Technique\n",
    "adasyn_results = RandomSamplingADASYN(df, 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the results\n",
    "results_df = pd.concat([baseline_results, smote_results, adasyn_results])\n",
    "# Print results\n",
    "print(results_df)\n",
    "results_df.to_csv('Results/CreditCardFraud.OneClassLearningResults.csv', index=False)\n",
    "# Plot a Classifier vs Recall Graph -> To evaluate how well the model is performing to detect the fraudulent transactions (minority class)\n",
    "plot_model_recall_graph(results_df)\n",
    "# Plot a Classifier vs Precision Graph -> To evaluate how precise the model is to detect the minority class (can be used as a secondary metric for evaluation)\n",
    "plot_model_precision_graph(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
