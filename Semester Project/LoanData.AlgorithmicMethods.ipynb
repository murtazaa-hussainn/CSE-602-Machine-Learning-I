{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Semester Project\n",
    "## Murtaza Hussain (29449) and Muhammad Asad ur Rehman (29456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance Problem\n",
    "\n",
    "The below code solves the prevalent problem of imbalanced dataset, where one class dominates the dataset as compared to the other. Such is the case for the following dataset for Credit Card Transactions to detect Fraudulent Transactions. We will evaluate the following methods to resolve Class Imbalance:\n",
    "1. Random Under Sampling\n",
    "2. Algorithmic Methods (Using Random Forest as well as modifying Class Weights)\n",
    "3. Anomaly Detection Method\n",
    "\n",
    "For the following Dataset, we will use the following 5 Algorithms to draw a comparision between different methods:\n",
    "1. Logistic Regression\n",
    "2. K-Nearest Neighbors (KNN)\n",
    "3. Random Forest\n",
    "4. Support Vector Machines (SVM)\n",
    "5. Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import make_scorer, recall_score, precision_score, f1_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader loads data from CSV Files\n",
    "def load_dataset():\n",
    "    dataset = pd.read_csv(\"./Source.LoanData.csv\")\n",
    "    return dataset\n",
    "\n",
    "df = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performs a missing value analysis on each column of the dataset, helps you decide on what to do in cleaning process\n",
    "def null_check(df):\n",
    "    null_columns = []\n",
    "    for column in df.columns:\n",
    "        print(\"Column Name:\", column)\n",
    "        print(\"Column DataType:\", df[column].dtype)\n",
    "        if df[column].dtype != 'float64' and df[column].dtype != 'int64':\n",
    "            print(\"Column unique values:\", df[column].unique())\n",
    "        print(\"Column has null:\", df[column].isnull().any())\n",
    "\n",
    "        \n",
    "        if df[column].isnull().any() == True:\n",
    "            print(\"Column Null Count:\", df[column].isnull().sum())\n",
    "            null_columns.append(column)\n",
    "        print(\"\\n\")\n",
    "    return null_columns\n",
    "\n",
    "# null_check(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function drops any null columns and missing values\n",
    "# This is where you decide whether to remove NULL rows (which will reduce the size of Dataset) or remove NULL columns entirely. You can also choose a combination of both.\n",
    "def clean_data(df, drop_columns, missing_value = False):\n",
    "    # Remove unnecessary columns\n",
    "    df.drop(drop_columns, axis=1, inplace=True)\n",
    "    # Drop rows with any missing values\n",
    "    if missing_value == False:\n",
    "        df.dropna(inplace=True)\n",
    "    else:\n",
    "        df.fillna(missing_value, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "        %  count\n",
      "0  90.01   8045\n",
      "1   9.99    893 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murta\\AppData\\Local\\Temp\\ipykernel_2672\\1546166213.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  class0 = format(100 * a[0]/sum(a), \".2f\")\n",
      "C:\\Users\\murta\\AppData\\Local\\Temp\\ipykernel_2672\\1546166213.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  class1 = format(100 * a[1]/sum(a), \".2f\")\n",
      "C:\\Users\\murta\\AppData\\Local\\Temp\\ipykernel_2672\\1546166213.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  meta = pd.DataFrame([{ \"%\": class0, \"count\": a[0]},\n",
      "C:\\Users\\murta\\AppData\\Local\\Temp\\ipykernel_2672\\1546166213.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  { \"%\": class1, \"count\": a[1]}])\n"
     ]
    }
   ],
   "source": [
    "# Prints a summary of class instances and distribution\n",
    "def data_summary(df, target=None):\n",
    "    if isinstance(df, pd.DataFrame) and target!=None:\n",
    "        a = df[target].value_counts()\n",
    "    else:\n",
    "        a = df.value_counts()\n",
    "    class0 = format(100 * a[0]/sum(a), \".2f\")\n",
    "    class1 = format(100 * a[1]/sum(a), \".2f\")\n",
    "\n",
    "    meta = pd.DataFrame([{ \"%\": class0, \"count\": a[0]},\n",
    "                         { \"%\": class1, \"count\": a[1]}])\n",
    "    print(\"\\nClass Distribution:\\n\", meta, \"\\n\")\n",
    "\n",
    "data_summary(df,'not.fully.paid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Index(['credit.policy', 'purpose', 'fico', 'revol.bal', 'inq.last.6mths',\n",
      "       'delinq.2yrs', 'pub.rec', 'not.fully.paid'],\n",
      "      dtype='object')\n",
      "Numerical columns: Index(['int.rate', 'installment', 'log.annual.inc', 'dti', 'days.with.cr.line',\n",
      "       'revol.util'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Transforms categorical and numberical data into numerical data\n",
    "def transform_data(df):\n",
    "    # Encode categorical variables\n",
    "    label_encoder = LabelEncoder()\n",
    "    print(\"Categorical columns:\", df.select_dtypes(include=['object', 'int64']).columns)\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "    \n",
    "    # Standardize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    print(\"Numerical columns:\", df.select_dtypes(include=['float64']).columns)\n",
    "    numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    if len(numerical_cols) > 0:\n",
    "        df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "    return df\n",
    "\n",
    "df = transform_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the results for Baseline Model were not promising for the original dataset, Feature selection is required\n",
    "def select_best_features_by_rfe(X, y, model=None, step=1, min_features=1, max_features=None):\n",
    "    if model is None:\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "    if max_features is None:\n",
    "        max_features = X.shape[1]\n",
    "\n",
    "    best_score = 0\n",
    "    best_num_features = min_features\n",
    "    best_features = []\n",
    "\n",
    "    # Loop over possible number of features from max_features to min_features\n",
    "    for n_features_to_select in range(max_features, min_features - 1, -step):\n",
    "        selector = RFE(model, n_features_to_select=n_features_to_select, step=step)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        selector.fit(X_train, y_train)\n",
    "        selected_features = X.columns[selector.support_]\n",
    "        y_pred = selector.predict(X_test)\n",
    "        score = f1_score(y_test, y_pred, pos_label=1)\n",
    "        \n",
    "        print(f\"Testing {n_features_to_select} features: F1 Score = {score}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_num_features = n_features_to_select\n",
    "            best_features = selected_features.tolist()\n",
    "\n",
    "    print(f\"Best F1 Score: {best_score} with {best_num_features} features. {best_features}\")\n",
    "\n",
    "    return best_features, best_num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 13 features: F1 Score = 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "when `importance_getter=='auto'`, the underlying estimator SVC should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m---> 57\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mBaselineRunAll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnot.fully.paid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m, in \u001b[0;36mBaselineRunAll\u001b[1;34m(df, target_name, k)\u001b[0m\n\u001b[0;32m      6\u001b[0m y \u001b[38;5;241m=\u001b[39m df[target_name]\n\u001b[0;32m      7\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 9\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mselect_best_features_by_rfe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSVC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# pca = PCA(n_components=9)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# X = pca.fit_transform(X)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass Distribution for Baseline Run:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 16\u001b[0m, in \u001b[0;36mselect_best_features_by_rfe\u001b[1;34m(X, y, model, step, min_features, max_features)\u001b[0m\n\u001b[0;32m     14\u001b[0m selector \u001b[38;5;241m=\u001b[39m RFE(model, n_features_to_select\u001b[38;5;241m=\u001b[39mn_features_to_select, step\u001b[38;5;241m=\u001b[39mstep)\n\u001b[0;32m     15\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns[selector\u001b[38;5;241m.\u001b[39msupport_]\n\u001b[0;32m     18\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:235\u001b[0m, in \u001b[0;36mRFE.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32mc:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    296\u001b[0m estimator\u001b[38;5;241m.\u001b[39mfit(X[:, features], y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[1;32m--> 299\u001b[0m importances \u001b[38;5;241m=\u001b[39m \u001b[43m_get_feature_importances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimportance_getter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msquare\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m ranks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(importances)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# for sparse case ranks is matrix\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_base.py:208\u001b[0m, in \u001b[0;36m_get_feature_importances\u001b[1;34m(estimator, getter, transform_func, norm_order)\u001b[0m\n\u001b[0;32m    206\u001b[0m         getter \u001b[38;5;241m=\u001b[39m attrgetter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_importances_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    209\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen `importance_getter==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`, the underlying \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    210\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    211\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`coef_` or `feature_importances_` attribute. Either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass a fitted estimator to feature selector or call fit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore calling transform.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     getter \u001b[38;5;241m=\u001b[39m attrgetter(getter)\n",
      "\u001b[1;31mValueError\u001b[0m: when `importance_getter=='auto'`, the underlying estimator SVC should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform."
     ]
    }
   ],
   "source": [
    "# Runs Baseline Model for All 5 Algorithms\n",
    "def BaselineRunAll(df, target_name, k=5):\n",
    "\n",
    "    # Separate features and targets\n",
    "    X = df.drop(target_name, axis=1)\n",
    "    y = df[target_name]\n",
    "    results = []\n",
    "\n",
    "    features = select_best_features_by_rfe(X,y, SVC(probability=True))\n",
    "\n",
    "\n",
    "    # pca = PCA(n_components=9)\n",
    "    # X = pca.fit_transform(X)\n",
    "\n",
    "    print(\"Class Distribution for Baseline Run:\")\n",
    "    data_summary(y)\n",
    "\n",
    "    # Initialize the classifiers\n",
    "    lr_classifier = LogisticRegression(max_iter=1000)\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "    knn_classifier = KNeighborsClassifier()\n",
    "    svm_classifier = SVC(probability=True)\n",
    "    nb_classifier = GaussianNB()\n",
    "    \n",
    "\n",
    "    # Initialize k-fold cross-validation where folds = 10\n",
    "    k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)     # The reasoning behind k = 10 is so as to strike a balance between test and train samples of minority class\n",
    "\n",
    "    # Define a recall and precision scorer specifically focusing on the minority class\n",
    "    recall_precision_scorer = {'recall': make_scorer(recall_score, pos_label=1), # As the majority class has 99.81% presence, accuracy cannot be used as a metric to evaluate performance\n",
    "                               'precision': make_scorer(precision_score, pos_label=1)}\n",
    "    \n",
    "    classifiers = {\n",
    "        'Logistic Regression': lr_classifier,\n",
    "        'Random Forest': rf_classifier,\n",
    "        'K-Nearest Neighbours': knn_classifier,\n",
    "        'Support Vector Machines': svm_classifier,\n",
    "        'Naive Bayes': nb_classifier\n",
    "    }\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        scores = cross_validate(clf, X, y, cv=k_fold, scoring=recall_precision_scorer)\n",
    "        print(f\"{clf_name} Model Training Completed\")\n",
    "        mean_recall = scores['test_recall'].mean()\n",
    "        mean_precision = scores['test_precision'].mean()\n",
    "\n",
    "        results.append({\n",
    "            'Method': 'Baseline',\n",
    "            'Classifier': clf_name,\n",
    "            'Class 1 Recall': mean_recall,\n",
    "            'Class 1 Precision': mean_precision\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "results = BaselineRunAll(df, 'not.fully.paid')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution for Baseline Run:\n",
      "\n",
      "Class Distribution:\n",
      "        %  count\n",
      "0  90.01   8045\n",
      "1   9.99    893 \n",
      "\n",
      "Logistic Regression Model Training Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Training Completed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\", line 235, in fit\n    return self._fit(X, y, **fit_params)\n  File \"c:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\", line 299, in _fit\n    importances = _get_feature_importances(\n  File \"c:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_base.py\", line 208, in _get_feature_importances\n    raise ValueError(\nValueError: when `importance_getter=='auto'`, the underlying estimator KNeighborsClassifier should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m     df_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_results\n\u001b[1;32m---> 57\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mBaselineRunAll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnot.fully.paid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "Cell \u001b[1;32mIn[6], line 42\u001b[0m, in \u001b[0;36mBaselineRunAll\u001b[1;34m(df, target_name, k, n_features_to_select)\u001b[0m\n\u001b[0;32m     38\u001b[0m recall_precision_scorer \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(recall_score, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     39\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(precision_score, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)}\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m clf_name, clf \u001b[38;5;129;01min\u001b[39;00m classifiers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 42\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecall_precision_scorer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclf_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Model Training Completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m     mean_recall \u001b[38;5;241m=\u001b[39m scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_recall\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mc:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\", line 235, in fit\n    return self._fit(X, y, **fit_params)\n  File \"c:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\", line 299, in _fit\n    importances = _get_feature_importances(\n  File \"c:\\Users\\murta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_base.py\", line 208, in _get_feature_importances\n    raise ValueError(\nValueError: when `importance_getter=='auto'`, the underlying estimator KNeighborsClassifier should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.\n"
     ]
    }
   ],
   "source": [
    "# Runs Baseline Model for All 5 Algorithms\n",
    "def BaselineRunAll(df, target_name, k=5, n_features_to_select=None):\n",
    "\n",
    "    # Separate features and targets\n",
    "    X = df.drop(target_name, axis=1)\n",
    "    y = df[target_name]\n",
    "    results = []\n",
    "\n",
    "    print(\"Class Distribution for Baseline Run:\")\n",
    "    data_summary(y)\n",
    "\n",
    "    # If n_features_to_select is not set, use half of the available features\n",
    "    if n_features_to_select is None:\n",
    "        n_features_to_select = X.shape[1] // 2\n",
    "\n",
    "    # Initialize the classifiers\n",
    "    lr_classifier = LogisticRegression(max_iter=1000)\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "    knn_classifier = KNeighborsClassifier()\n",
    "    svm_classifier = SVC(kernel='linear')  # Ensure linear kernel for feature ranking in SVC\n",
    "    nb_classifier = GaussianNB()\n",
    "    \n",
    "    # Wrap classifiers with RFE\n",
    "    classifiers = {\n",
    "        'Logistic Regression': RFE(lr_classifier, n_features_to_select=n_features_to_select),\n",
    "        'Random Forest': RFE(rf_classifier, n_features_to_select=n_features_to_select),\n",
    "        'K-Nearest Neighbours': RFE(knn_classifier, n_features_to_select=n_features_to_select),\n",
    "        'Support Vector Machines': RFE(svm_classifier, n_features_to_select=n_features_to_select),\n",
    "        'Naive Bayes': RFE(nb_classifier, n_features_to_select=n_features_to_select, step=1)\n",
    "    }\n",
    "\n",
    "    # Initialize k-fold cross-validation where folds = 10\n",
    "    k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Define a recall and precision scorer specifically focusing on the minority class\n",
    "    recall_precision_scorer = {'recall': make_scorer(recall_score, pos_label=1),\n",
    "                               'precision': make_scorer(precision_score, pos_label=1)}\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        scores = cross_validate(clf, X, y, cv=k_fold, scoring=recall_precision_scorer)\n",
    "        print(f\"{clf_name} Model Training Completed\")\n",
    "        mean_recall = scores['test_recall'].mean()\n",
    "        mean_precision = scores['test_precision'].mean()\n",
    "\n",
    "        results.append({\n",
    "            'Method': 'Baseline with RFE',\n",
    "            'Classifier': clf_name,\n",
    "            'Class 1 Recall': mean_recall,\n",
    "            'Class 1 Precision': mean_precision\n",
    "        })\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n",
    "\n",
    "results = BaselineRunAll(df, 'not.fully.paid')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies Class Weighting (A method to add additional weightage to learn patterns from minority class)\n",
    "def ClassWeightingMethod(df, target_name, k=5):\n",
    "\n",
    "    # Separate features and targets\n",
    "    X = df.drop(target_name, axis=1)\n",
    "    y = df[target_name]\n",
    "    results = []\n",
    "\n",
    "    pca = PCA(n_components=20)\n",
    "    X = pca.fit_transform(X)\n",
    "\n",
    "    print(\"Class Distribution for Class Weighting Method:\")\n",
    "    data_summary(y)\n",
    "\n",
    "    # Calculating priors for GaussianNB\n",
    "    priors = y.value_counts()\n",
    "    priors = priors/sum(priors)\n",
    "\n",
    "    # Initialize the classifiers with settings\n",
    "    lr_classifier = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "    rf_classifier = RandomForestClassifier(class_weight='balanced')\n",
    "    knn_classifier = KNeighborsClassifier() # KNN does not support class_weight as the algorithm is mainly based on clustering\n",
    "    svm_classifier = SVC(class_weight='balanced')\n",
    "    nb_classifier = GaussianNB(priors=priors)\n",
    "\n",
    "    # Initialize k-fold cross-validation where folds = 10\n",
    "    k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Define a recall and precision scorer specifically focusing on the minority class\n",
    "    recall_precision_scorer = {'recall': make_scorer(recall_score, pos_label=1), \n",
    "                               'precision': make_scorer(precision_score, pos_label=1)}\n",
    "\n",
    "    classifiers = {\n",
    "        'Logistic Regression': lr_classifier,\n",
    "        'Random Forest': rf_classifier,\n",
    "        'K-Nearest Neighbours': knn_classifier,\n",
    "        'Support Vector Machines': svm_classifier,\n",
    "        'Naive Bayes': nb_classifier\n",
    "    }\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        scores = cross_validate(clf, X, y, cv=k_fold, scoring=recall_precision_scorer)\n",
    "        print(f\"{clf_name} Model Training Completed\")\n",
    "        mean_recall = scores['test_recall'].mean()\n",
    "        mean_precision = scores['test_precision'].mean()\n",
    "\n",
    "        results.append({\n",
    "            'Method': 'Class Weighting',\n",
    "            'Classifier': clf_name,\n",
    "            'Class 1 Recall': mean_recall,\n",
    "            'Class 1 Precision': mean_precision\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# results = ClassWeightingMethod(df, 'not.fully.paid')\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies Bagging (Algorithmic Methods) to learn minority class\n",
    "def BaggingAlgorithmicMethod(df, target_name, k=5):\n",
    "\n",
    "    # Separate features and targets\n",
    "    X = df.drop(target_name, axis=1)\n",
    "    y = df[target_name]\n",
    "    results = []\n",
    "\n",
    "    pca = PCA(n_components=20)\n",
    "    X = pca.fit_transform(X)\n",
    "\n",
    "    print(\"Class Distribution for Bagging Method:\")\n",
    "    data_summary(y)\n",
    "\n",
    "\n",
    "    # Initialize the classifiers with Bagging\n",
    "    lr_classifier = BaggingClassifier(estimator=LogisticRegression(max_iter=1000), random_state=42)\n",
    "    rf_classifier = RandomForestClassifier() # Already an ensemble method (Bagging Algorithm) \n",
    "    knn_classifier = BaggingClassifier(estimator=KNeighborsClassifier(), random_state=42)\n",
    "    svm_classifier = BaggingClassifier(estimator=SVC(), random_state=42)\n",
    "    nb_classifier = BaggingClassifier(estimator=GaussianNB(), random_state=42)\n",
    "\n",
    "    # Initialize k-fold cross-validation where folds = 10\n",
    "    k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Define a recall and precision scorer specifically focusing on the minority class\n",
    "    recall_precision_scorer = {'recall': make_scorer(recall_score, pos_label=1), \n",
    "                               'precision': make_scorer(precision_score, pos_label=1)}\n",
    "\n",
    "    classifiers = {\n",
    "        'Logistic Regression': lr_classifier,\n",
    "        'Random Forest': rf_classifier,\n",
    "        'K-Nearest Neighbours': knn_classifier,\n",
    "        'Support Vector Machines': svm_classifier,\n",
    "        'Naive Bayes': nb_classifier\n",
    "    }\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        scores = cross_validate(clf, X, y, cv=k_fold, scoring=recall_precision_scorer)\n",
    "        print(f\"{clf_name} Model Training Completed\")\n",
    "        mean_recall = scores['test_recall'].mean()\n",
    "        mean_precision = scores['test_precision'].mean()\n",
    "\n",
    "        results.append({\n",
    "            'Method': 'Bagging (Algorithmic Method)',\n",
    "            'Classifier': clf_name,\n",
    "            'Class 1 Recall': mean_recall,\n",
    "            'Class 1 Precision': mean_precision\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# results = BaggingAlgorithmicMethod(df, 'not.fully.paid')\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs Boosting (Algorithmic Method) to learn minority class\n",
    "def BoostingAlgorithmicMethod(df, target_name, k=5):\n",
    "\n",
    "    # Separate features and targets\n",
    "    X = df.drop(target_name, axis=1)\n",
    "    y = df[target_name]\n",
    "    results = []\n",
    "\n",
    "    pca = PCA(n_components=20)\n",
    "    X = pca.fit_transform(X)\n",
    "\n",
    "    print(\"Class Distribution for Boosting Run:\")\n",
    "    data_summary(y)\n",
    "\n",
    "    # Initialize the classifiers with Boosting\n",
    "    lr_classifier = AdaBoostClassifier(estimator=LogisticRegression(max_iter=1000), random_state=42, algorithm=\"SAMME\")\n",
    "    rf_classifier = RandomForestClassifier() # Already an ensemble method (Bagging Algorithm) \n",
    "    knn_classifier = KNeighborsClassifier() # Does not support weighting samples which is required for Boosting\n",
    "    svm_classifier = SVC() # Is slow to train with Boosting Algorithm and requires probability estimation hence can be extremely time consuming as Boosting Algorithm performs multiple iterations\n",
    "    nb_classifier = AdaBoostClassifier(estimator=GaussianNB(), random_state=42, algorithm=\"SAMME\")\n",
    "\n",
    "    # Initialize k-fold cross-validation where folds = 10\n",
    "    k_fold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Define a recall and precision scorer specifically focusing on the minority class\n",
    "    recall_precision_scorer = {'recall': make_scorer(recall_score, pos_label=1), \n",
    "                               'precision': make_scorer(precision_score, pos_label=1)}\n",
    "\n",
    "    classifiers = {\n",
    "        'Logistic Regression': lr_classifier,\n",
    "        'Random Forest': rf_classifier,\n",
    "        'K-Nearest Neighbours': knn_classifier,\n",
    "        'Support Vector Machines': svm_classifier,\n",
    "        'Naive Bayes': nb_classifier\n",
    "    }\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        scores = cross_validate(clf, X, y, cv=k_fold, scoring=recall_precision_scorer)\n",
    "        print(f\"{clf_name} Model Training Completed\")\n",
    "        mean_recall = scores['test_recall'].mean()\n",
    "        mean_precision = scores['test_precision'].mean()\n",
    "\n",
    "        results.append({\n",
    "            'Method': 'Boosting (Algorithmic Method)',\n",
    "            'Classifier': clf_name,\n",
    "            'Class 1 Recall': mean_recall,\n",
    "            'Class 1 Precision': mean_precision\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# results = RandomSamplingADASYN(df, 'not.fully.paid')\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Model vs Recall graph for Classification Dataset for Each Method\n",
    "def plot_model_recall_graph(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plotting lines for each Method\n",
    "    sns.lineplot(data=df, x='Classifier', y='Class 1 Recall', hue='Method', marker='o')\n",
    "\n",
    "    plt.title('Classifier vs Recall')\n",
    "    plt.xlabel('Classifier')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend(title='Method')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Model vs Precision graph for Classification Dataset for Each Method\n",
    "def plot_model_precision_graph(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plotting lines for each Method\n",
    "    sns.lineplot(data=df, x='Classifier', y='Class 1 Precision', hue='Method', marker='o')\n",
    "\n",
    "    plt.title('Classifier vs Precision')\n",
    "    plt.xlabel('Classifier')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend(title='Method')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_workflow():\n",
    "    # Load Dataset\n",
    "    df = load_dataset()\n",
    "    # No need for Data Cleaning and EDA as Data is already clean\n",
    "    # Evaluate Class Distribution of the cleaned Dataset\n",
    "    data_summary(df,'not.fully.paid')\n",
    "    # Transform and Encode Data\n",
    "    df = transform_data(df)\n",
    "    # Run Baseline Models using k = 5\n",
    "    baseline_results = BaselineRunAll(df, 'not.fully.paid')\n",
    "    # Evaluate Models using Class Weight Adjustment Technique\n",
    "    class_weighting_results = ClassWeightingMethod(df, 'not.fully.paid')\n",
    "    # Evaluate Models using Bagging Algorithm\n",
    "    bagging_results = BaggingAlgorithmicMethod(df, 'not.fully.paid')\n",
    "    # Evaluate Models using Boosting Algorithm\n",
    "    boosting_results = BoostingAlgorithmicMethod(df, 'not.fully.paid')\n",
    "    # Concatenate the results\n",
    "    results_df = pd.concat([baseline_results, class_weighting_results, bagging_results, boosting_results])\n",
    "    # Print results\n",
    "    print(results_df)\n",
    "    results_df.to_csv('Results/CreditCardFraud.AlgorithmicMethodsResults.csv', index=False)\n",
    "    # Plot a Classifier vs Recall Graph -> To evaluate how well the model is performing to detect the fraudulent transactions (minority class)\n",
    "    plot_model_recall_graph(results_df)\n",
    "    # Plot a Classifier vs Precision Graph -> To evaluate how precise the model is to detect the minority class (can be used as a secondary metric for evaluation)\n",
    "    plot_model_precision_graph(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the pipeline was not running in one go, we had to split it into smaller parts\n",
    "# master_workflow() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broken down pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = load_dataset()\n",
    "# No need for Data Cleaning and EDA as Data is already clean\n",
    "# Evaluate Class Distribution of the cleaned Dataset\n",
    "data_summary(df,'not.fully.paid')\n",
    "# Transform and Encode Data\n",
    "df = transform_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Baseline Models using k = 10\n",
    "baseline_results = BaselineRunAll(df, 'not.fully.paid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models using Class Weight Adjustment Technique\n",
    "class_weighting_results = ClassWeightingMethod(df, 'not.fully.paid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models using Bagging Algorithm\n",
    "bagging_results = BaggingAlgorithmicMethod(df, 'not.fully.paid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models using Boosting Algorithm\n",
    "boosting_results = BoostingAlgorithmicMethod(df, 'not.fully.paid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the results\n",
    "results_df = pd.concat([baseline_results, class_weighting_results, bagging_results, boosting_results])\n",
    "# Print results\n",
    "print(results_df)\n",
    "results_df.to_csv('Results/LoanData.AlgorithmicMethodsResults.csv', index=False)\n",
    "# Plot a Classifier vs Recall Graph -> To evaluate how well the model is performing to detect the fraudulent transactions (minority class)\n",
    "plot_model_recall_graph(results_df)\n",
    "# Plot a Classifier vs Precision Graph -> To evaluate how precise the model is to detect the minority class (can be used as a secondary metric for evaluation)\n",
    "plot_model_precision_graph(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
