{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa4a549e",
   "metadata": {},
   "source": [
    "# Machine Learning Excel Assignment \n",
    "## Murtaza Hussain (29449) and Muhammad Asad ur Rehman (29456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f26133ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, classification_report, r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE, chi2, SequentialFeatureSelector\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from IPython.display import display\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba375ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader loads data from UCI-ML Repo\n",
    "def load_datasets():\n",
    "    # Classification Datasets\n",
    "    c_cancer = pd.read_csv(\"./Classification.CancerMB.csv\").iloc[:, :32]\n",
    "    # Regression Datasets\n",
    "    r_life_expectancy = pd.read_csv(\"./Regression.Life.Expectancy.csv\")\n",
    "    \n",
    "    return c_cancer, r_life_expectancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa58952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performs a missing value analysis on each column of the dataset, helps you decide on what to do in cleaning process\n",
    "def null_check(df):\n",
    "    null_columns = []\n",
    "    for column in df.columns:\n",
    "        print(\"Column Name:\", column)\n",
    "        print(\"Column DataType:\", df[column].dtype)\n",
    "        if df[column].dtype != 'float64' and df[column].dtype != 'int64':\n",
    "            print(\"Column unique values:\", df[column].unique())\n",
    "        print(\"Column has null:\", df[column].isnull().any())\n",
    "\n",
    "        \n",
    "        if df[column].isnull().any() == True:\n",
    "            print(\"Column Null Count:\", df[column].isnull().sum())\n",
    "            null_columns.append(column)\n",
    "        print(\"\\n\")\n",
    "    return null_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b47f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function drops any null columns and missing values\n",
    "# This is where you decide whether to remove NULL rows (which will reduce the size of Dataset) or remove NULL columns entirely. You can also choose a combination of both.\n",
    "def clean_data(df, drop_columns, missing_value = False):\n",
    "    # Remove unnecessary columns\n",
    "    df.drop(drop_columns, axis=1, inplace=True)\n",
    "    # Drop rows with any missing values\n",
    "    if missing_value == False:\n",
    "        df.dropna(inplace=True)\n",
    "    else:\n",
    "        df.fillna(missing_value, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e773146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms categorical and numberical data into numerical data\n",
    "def transform_data(df):\n",
    "    # Encode categorical variables\n",
    "    label_encoder = LabelEncoder()\n",
    "    # print(\"Categorical columns:\", df.select_dtypes(include=['object']).columns)\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "    \n",
    "    # Standardize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    # print(\"Numerical columns:\", df.select_dtypes(include=['float64', 'int64']).columns)\n",
    "    numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    if len(numerical_cols) > 0:\n",
    "        df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea0fad7",
   "metadata": {},
   "source": [
    "# Classificiation Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2fc5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNScore(data, target_col, cv_splits):\n",
    "    # Split dataset into features and target variable\n",
    "    X = data.drop(target_col, axis=1)\n",
    "    y = data[target_col]\n",
    "\n",
    "    # Initialize KFold with different values\n",
    "    results = {}\n",
    "\n",
    "    for cv in cv_splits:\n",
    "        k_fold = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "        # Lists to store scores\n",
    "        knn_f1_positive_scores = []\n",
    "        knn_f1_negative_scores = []\n",
    "        knn_auc_scores = []\n",
    "        knn_accuracy_scores = []\n",
    "\n",
    "        for train_index, test_index in k_fold.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Standardize features by removing the mean and scaling to unit variance\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            # KNN Classifier\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "            knn_classifier.fit(X_train_scaled, y_train)\n",
    "            knn_y_pred = knn_classifier.predict(X_test_scaled)\n",
    "\n",
    "            # Calculate evaluation metrics for KNN\n",
    "            knn_f1_positive_scores.append(f1_score(y_test, knn_y_pred, pos_label=1))\n",
    "            knn_f1_negative_scores.append(f1_score(y_test, knn_y_pred, pos_label=0))\n",
    "            knn_auc_scores.append(roc_auc_score(y_test, knn_y_pred))\n",
    "            knn_accuracy_scores.append(accuracy_score(y_test, knn_y_pred))\n",
    "\n",
    "        # Calculate average scores\n",
    "        avg_f1_positive_score = sum(knn_f1_positive_scores) / len(knn_f1_positive_scores)\n",
    "        avg_f1_negative_score = sum(knn_f1_negative_scores) / len(knn_f1_negative_scores)\n",
    "        avg_auc_score = sum(knn_auc_scores) / len(knn_auc_scores)\n",
    "        avg_accuracy = sum(knn_accuracy_scores) / len(knn_accuracy_scores)\n",
    "\n",
    "        # Store results\n",
    "        results[f'CV_{cv}'] = {\n",
    "            'F1 Score (Positive)': avg_f1_positive_score,\n",
    "            'F1 Score (Negative)': avg_f1_negative_score,\n",
    "            'AUC Score': avg_auc_score,\n",
    "            'Accuracy': avg_accuracy\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame.from_dict(results, orient='index', columns=['F1 Score (Positive)', 'F1 Score (Negative)', 'AUC Score', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33583631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegressionScore(data, target_col, cv_splits):\n",
    "    # Split dataset into features and target variable\n",
    "    X = data.drop(target_col, axis=1)\n",
    "    y = data[target_col]\n",
    "\n",
    "    # Initialize dictionary to store results\n",
    "    results = {}\n",
    "\n",
    "    for cv in cv_splits:\n",
    "        # Initialize KFold\n",
    "        k_fold = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "        # Lists to store scores\n",
    "        log_reg_f1_positive_scores = []\n",
    "        log_reg_f1_negative_scores = []\n",
    "        log_reg_auc_scores = []\n",
    "        log_reg_accuracy_scores = []\n",
    "\n",
    "        for train_index, test_index in k_fold.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Standardize features by removing the mean and scaling to unit variance\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            # Logistic Regression\n",
    "            log_reg_classifier = LogisticRegression()\n",
    "            log_reg_classifier.fit(X_train_scaled, y_train)\n",
    "            log_reg_y_pred = log_reg_classifier.predict(X_test_scaled)\n",
    "\n",
    "            # Calculate evaluation metrics for Logistic Regression\n",
    "            log_reg_f1_positive_scores.append(f1_score(y_test, log_reg_y_pred, pos_label=1))\n",
    "            log_reg_f1_negative_scores.append(f1_score(y_test, log_reg_y_pred, pos_label=0))\n",
    "            log_reg_auc_scores.append(roc_auc_score(y_test, log_reg_y_pred))\n",
    "            log_reg_accuracy_scores.append(accuracy_score(y_test, log_reg_y_pred))\n",
    "\n",
    "        # Calculate average scores\n",
    "        avg_f1_positive_score = sum(log_reg_f1_positive_scores) / len(log_reg_f1_positive_scores)\n",
    "        avg_f1_negative_score = sum(log_reg_f1_negative_scores) / len(log_reg_f1_negative_scores)\n",
    "        avg_auc_score = sum(log_reg_auc_scores) / len(log_reg_auc_scores)\n",
    "        avg_accuracy = sum(log_reg_accuracy_scores) / len(log_reg_accuracy_scores)\n",
    "\n",
    "        # Store results\n",
    "        results[f'CV_{cv}'] = {\n",
    "            'F1 Score (Positive)': avg_f1_positive_score,\n",
    "            'F1 Score (Negative)': avg_f1_negative_score,\n",
    "            'AUC Score': avg_auc_score,\n",
    "            'Accuracy': avg_accuracy\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame.from_dict(results, orient='index', columns=['F1 Score (Positive)', 'F1 Score (Negative)', 'AUC Score', 'Accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77e75ec",
   "metadata": {},
   "source": [
    "# Regression Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30f7be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNRegressionMetrics(data, target_col, cv_splits):\n",
    "    # Split dataset into features and target variable\n",
    "    X = data.drop(target_col, axis=1)\n",
    "    y = data[target_col]\n",
    "    \n",
    "    # Define the number of neighbors for KNN\n",
    "    n_neighbors = 5\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for cv in cv_splits:\n",
    "        # Initialize lists to store scores for each CV split\n",
    "        mae_scores = []\n",
    "        mse_scores = []\n",
    "        rmse_scores = []\n",
    "        r_squared_scores = []\n",
    "        aic_scores = []\n",
    "        bic_scores = []\n",
    "        p_values_list = []\n",
    "\n",
    "        # Initialize KFold\n",
    "        k_fold = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "        for train_index, test_index in k_fold.split(X):\n",
    "            # Reset scores for each fold within a CV split\n",
    "            fold_mae = []\n",
    "            fold_mse = []\n",
    "            fold_rmse = []\n",
    "            fold_r_squared = []\n",
    "            fold_aic = []\n",
    "            fold_bic = []\n",
    "            fold_p_values = []\n",
    "\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Standardize features by removing the mean and scaling to unit variance\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            # KNN Regressor\n",
    "            knn_regressor = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "            knn_regressor.fit(X_train_scaled, y_train)\n",
    "            y_pred = knn_regressor.predict(X_test_scaled)\n",
    "\n",
    "            # Calculate evaluation metrics for this fold\n",
    "            fold_mae.append(mean_absolute_error(y_test, y_pred))\n",
    "            fold_mse.append(mean_squared_error(y_test, y_pred))\n",
    "            fold_rmse.append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "            fold_r_squared.append(r2_score(y_test, y_pred))\n",
    "\n",
    "            # AIC, BIC, and p-values using OLS regression\n",
    "            X_train_sm = sm.add_constant(X_train)\n",
    "            ols_model = sm.OLS(y_train, X_train_sm)\n",
    "            ols_results = ols_model.fit()\n",
    "            fold_aic.append(ols_results.aic)\n",
    "            fold_bic.append(ols_results.bic)\n",
    "            fold_p_values.append(ols_results.pvalues.drop('const'))  # Exclude p-value of intercept\n",
    "\n",
    "            # Append scores for this fold\n",
    "            mae_scores.append(fold_mae)\n",
    "            mse_scores.append(fold_mse)\n",
    "            rmse_scores.append(fold_rmse)\n",
    "            r_squared_scores.append(fold_r_squared)\n",
    "            aic_scores.append(fold_aic)\n",
    "            bic_scores.append(fold_bic)\n",
    "            p_values_list.append(fold_p_values)\n",
    "\n",
    "        # Calculate average scores across all folds for this CV split\n",
    "        avg_mae = np.mean(mae_scores)\n",
    "        avg_mse = np.mean(mse_scores)\n",
    "        avg_rmse = np.mean(rmse_scores)\n",
    "        avg_r_squared = np.mean(r_squared_scores)\n",
    "        avg_aic = np.mean(aic_scores)\n",
    "        avg_bic = np.mean(bic_scores)\n",
    "        avg_p_values = np.mean(p_values_list, axis=0)  # Take the mean along the columns\n",
    "\n",
    "        # Store results\n",
    "        results[f'CV_{cv}'] = {\n",
    "            'MAE': avg_mae,\n",
    "            'MSE': avg_mse,\n",
    "            'RMSE': avg_rmse,\n",
    "            'R-Squared': avg_r_squared,\n",
    "            'AIC': avg_aic,\n",
    "            'BIC': avg_bic,\n",
    "            'P-Values': avg_p_values\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame.from_dict(results, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83739128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLSRegressionMetrics(data, target_col, cv_splits):\n",
    "    # Split dataset into features and target variable\n",
    "    X = data.drop(target_col, axis=1)\n",
    "    y = data[target_col]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for cv in cv_splits:\n",
    "        # Initialize KFold\n",
    "        k_fold = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "        # Lists to store scores\n",
    "        mae_scores = []\n",
    "        mse_scores = []\n",
    "        rmse_scores = []\n",
    "        r_squared_scores = []\n",
    "        aic_scores = []\n",
    "        bic_scores = []\n",
    "        p_values_list = []\n",
    "\n",
    "        for train_index, test_index in k_fold.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Standardize features by removing the mean and scaling to unit variance\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            # Add constant to features for OLS\n",
    "            X_train_sm = sm.add_constant(X_train_scaled)\n",
    "\n",
    "            # OLS Regression\n",
    "            ols_model = sm.OLS(y_train, X_train_sm)\n",
    "            ols_results = ols_model.fit()\n",
    "\n",
    "            # Predictions\n",
    "            X_test_sm = sm.add_constant(X_test_scaled)\n",
    "            y_pred = ols_results.predict(X_test_sm)\n",
    "\n",
    "            # Calculate evaluation metrics\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            r_squared = r2_score(y_test, y_pred)\n",
    "            aic = ols_results.aic\n",
    "            bic = ols_results.bic\n",
    "            p_values = ols_results.pvalues.drop('const')  # Exclude p-value of intercept\n",
    "\n",
    "            # Append scores\n",
    "            mae_scores.append(mae)\n",
    "            mse_scores.append(mse)\n",
    "            rmse_scores.append(rmse)\n",
    "            r_squared_scores.append(r_squared)\n",
    "            aic_scores.append(aic)\n",
    "            bic_scores.append(bic)\n",
    "            p_values_list.append(p_values)\n",
    "\n",
    "        # Calculate the average scores for each metric\n",
    "        avg_mae = np.mean(mae_scores)\n",
    "        avg_mse = np.mean(mse_scores)\n",
    "        avg_rmse = np.mean(rmse_scores)\n",
    "        avg_r_squared = np.mean(r_squared_scores)\n",
    "        avg_aic = np.mean(aic_scores)\n",
    "        avg_bic = np.mean(bic_scores)\n",
    "\n",
    "        # Flatten the nested lists of p-values\n",
    "        flattened_p_values = [item for sublist in p_values_list for item in sublist]\n",
    "\n",
    "        # Calculate the average p-value for each feature\n",
    "        avg_p_values = np.mean(flattened_p_values, axis=0)\n",
    "\n",
    "        # Store results\n",
    "        results[f'CV_{cv}'] = {\n",
    "            'MAE': avg_mae,\n",
    "            'MSE': avg_mse,\n",
    "            'RMSE': avg_rmse,\n",
    "            'R-Squared': avg_r_squared,\n",
    "            'AIC': avg_aic,\n",
    "            'BIC': avg_bic,\n",
    "            'P-Values': avg_p_values.tolist()  # Convert numpy array to list\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame.from_dict(results, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "266e3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all Datasets into the required variables\n",
    "c_cancer, r_life_expectancy = load_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6834541",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf1c513",
   "metadata": {},
   "source": [
    "## Dataset 1: Cancer Detection Dataset (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "183608f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name: id\n",
      "Column DataType: int64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: diagnosis\n",
      "Column DataType: object\n",
      "Column unique values: ['M' 'B']\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: radius_mean\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: texture_mean\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: perimeter_mean\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: area_mean\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: smoothness_mean\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: compactness_mean\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: concavity_mean\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: concave points_mean\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: symmetry_mean\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: fractal_dimension_mean\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: radius_se\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: texture_se\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: perimeter_se\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: area_se\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: smoothness_se\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: compactness_se\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: concavity_se\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: concave points_se\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: symmetry_se\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: fractal_dimension_se\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: radius_worst\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: texture_worst\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: perimeter_worst\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: area_worst\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: smoothness_worst\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: compactness_worst\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: concavity_worst\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: concave points_worst\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: symmetry_worst\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: fractal_dimension_worst\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n",
      "None\n",
      "\n",
      "Classification:\n",
      "\n",
      "KNN Classifier:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Score (Positive)</th>\n",
       "      <th>F1 Score (Negative)</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CV_5</th>\n",
       "      <td>0.9426</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>0.9490</td>\n",
       "      <td>0.9578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_10</th>\n",
       "      <td>0.9468</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.9648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_15</th>\n",
       "      <td>0.9551</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.9612</td>\n",
       "      <td>0.9683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F1 Score (Positive)  F1 Score (Negative)  AUC Score  Accuracy\n",
       "CV_5                0.9426               0.9665     0.9490    0.9578\n",
       "CV_10               0.9468               0.9729     0.9545    0.9648\n",
       "CV_15               0.9551               0.9744     0.9612    0.9683"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Score (Positive)</th>\n",
       "      <th>F1 Score (Negative)</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CV_5</th>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.9789</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.9736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_10</th>\n",
       "      <td>0.9626</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>0.9684</td>\n",
       "      <td>0.9718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_15</th>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.9806</td>\n",
       "      <td>0.9763</td>\n",
       "      <td>0.9771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F1 Score (Positive)  F1 Score (Negative)  AUC Score  Accuracy\n",
       "CV_5                0.9646               0.9789     0.9704    0.9736\n",
       "CV_10               0.9626               0.9768     0.9684    0.9718\n",
       "CV_15               0.9706               0.9806     0.9763    0.9771"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_cancer\n",
    "null_check(c_cancer)\n",
    "print(c_cancer.info())\n",
    "c_cancer = transform_data(c_cancer)\n",
    "\n",
    "# Define the number of splits for cross-validation\n",
    "cv_splits = [5, 10, 15]\n",
    "\n",
    "print(\"\\nClassification:\")\n",
    "knn_results = KNNScore(c_cancer, 'diagnosis', cv_splits)\n",
    "print(\"\\nKNN Classifier:\")\n",
    "display(knn_results)\n",
    "\n",
    "log_reg_results = LogisticRegressionScore(c_cancer, 'diagnosis', cv_splits)\n",
    "print(\"\\nLogistic Regression:\")\n",
    "display(log_reg_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a536d768",
   "metadata": {},
   "source": [
    "## Dataset 2: Life Expectancy Dataset (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00297c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name: Country\n",
      "Column DataType: object\n",
      "Column unique values: ['Afghanistan' 'Albania' 'Algeria' 'Angola' 'Antigua and Barbuda'\n",
      " 'Argentina' 'Armenia' 'Australia' 'Austria' 'Azerbaijan' 'Bahamas'\n",
      " 'Bahrain' 'Bangladesh' 'Barbados' 'Belarus' 'Belgium' 'Belize' 'Benin'\n",
      " 'Bhutan' 'Bolivia (Plurinational State of)' 'Bosnia and Herzegovina'\n",
      " 'Botswana' 'Brazil' 'Brunei Darussalam' 'Bulgaria' 'Burkina Faso'\n",
      " 'Burundi' \"Côte d'Ivoire\" 'Cabo Verde' 'Cambodia' 'Cameroon' 'Canada'\n",
      " 'Central African Republic' 'Chad' 'Chile' 'China' 'Colombia' 'Comoros'\n",
      " 'Congo' 'Cook Islands' 'Costa Rica' 'Croatia' 'Cuba' 'Cyprus' 'Czechia'\n",
      " \"Democratic People's Republic of Korea\"\n",
      " 'Democratic Republic of the Congo' 'Denmark' 'Djibouti' 'Dominica'\n",
      " 'Dominican Republic' 'Ecuador' 'Egypt' 'El Salvador' 'Equatorial Guinea'\n",
      " 'Eritrea' 'Estonia' 'Ethiopia' 'Fiji' 'Finland' 'France' 'Gabon' 'Gambia'\n",
      " 'Georgia' 'Germany' 'Ghana' 'Greece' 'Grenada' 'Guatemala' 'Guinea'\n",
      " 'Guinea-Bissau' 'Guyana' 'Haiti' 'Honduras' 'Hungary' 'Iceland' 'India'\n",
      " 'Indonesia' 'Iran (Islamic Republic of)' 'Iraq' 'Ireland' 'Israel'\n",
      " 'Italy' 'Jamaica' 'Japan' 'Jordan' 'Kazakhstan' 'Kenya' 'Kiribati'\n",
      " 'Kuwait' 'Kyrgyzstan' \"Lao People's Democratic Republic\" 'Latvia'\n",
      " 'Lebanon' 'Lesotho' 'Liberia' 'Libya' 'Lithuania' 'Luxembourg'\n",
      " 'Madagascar' 'Malawi' 'Malaysia' 'Maldives' 'Mali' 'Malta'\n",
      " 'Marshall Islands' 'Mauritania' 'Mauritius' 'Mexico'\n",
      " 'Micronesia (Federated States of)' 'Monaco' 'Mongolia' 'Montenegro'\n",
      " 'Morocco' 'Mozambique' 'Myanmar' 'Namibia' 'Nauru' 'Nepal' 'Netherlands'\n",
      " 'New Zealand' 'Nicaragua' 'Niger' 'Nigeria' 'Niue' 'Norway' 'Oman'\n",
      " 'Pakistan' 'Palau' 'Panama' 'Papua New Guinea' 'Paraguay' 'Peru'\n",
      " 'Philippines' 'Poland' 'Portugal' 'Qatar' 'Republic of Korea'\n",
      " 'Republic of Moldova' 'Romania' 'Russian Federation' 'Rwanda'\n",
      " 'Saint Kitts and Nevis' 'Saint Lucia' 'Saint Vincent and the Grenadines'\n",
      " 'Samoa' 'San Marino' 'Sao Tome and Principe' 'Saudi Arabia' 'Senegal'\n",
      " 'Serbia' 'Seychelles' 'Sierra Leone' 'Singapore' 'Slovakia' 'Slovenia'\n",
      " 'Solomon Islands' 'Somalia' 'South Africa' 'South Sudan' 'Spain'\n",
      " 'Sri Lanka' 'Sudan' 'Suriname' 'Swaziland' 'Sweden' 'Switzerland'\n",
      " 'Syrian Arab Republic' 'Tajikistan' 'Thailand'\n",
      " 'The former Yugoslav republic of Macedonia' 'Timor-Leste' 'Togo' 'Tonga'\n",
      " 'Trinidad and Tobago' 'Tunisia' 'Turkey' 'Turkmenistan' 'Tuvalu' 'Uganda'\n",
      " 'Ukraine' 'United Arab Emirates'\n",
      " 'United Kingdom of Great Britain and Northern Ireland'\n",
      " 'United Republic of Tanzania' 'United States of America' 'Uruguay'\n",
      " 'Uzbekistan' 'Vanuatu' 'Venezuela (Bolivarian Republic of)' 'Viet Nam'\n",
      " 'Yemen' 'Zambia' 'Zimbabwe']\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: Year\n",
      "Column DataType: int64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: Status\n",
      "Column DataType: object\n",
      "Column unique values: ['Developing' 'Developed']\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: Life expectancy \n",
      "Column DataType: float64\n",
      "Column has null: True\n",
      "Column Null Count: 10\n",
      "\n",
      "\n",
      "Column Name: Adult Mortality\n",
      "Column DataType: float64\n",
      "Column has null: True\n",
      "Column Null Count: 10\n",
      "\n",
      "\n",
      "Column Name: infant deaths\n",
      "Column DataType: int64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: Alcohol\n",
      "Column DataType: float64\n",
      "Column has null: True\n",
      "Column Null Count: 194\n",
      "\n",
      "\n",
      "Column Name: percentage expenditure\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: Hepatitis B\n",
      "Column DataType: float64\n",
      "Column has null: True\n",
      "Column Null Count: 553\n",
      "\n",
      "\n",
      "Column Name: Measles \n",
      "Column DataType: int64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name:  BMI \n",
      "Column DataType: float64\n",
      "Column has null: True\n",
      "Column Null Count: 34\n",
      "\n",
      "\n",
      "Column Name: under-five deaths \n",
      "Column DataType: int64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: Polio\n",
      "Column DataType: float64\n",
      "Column has null: True\n",
      "Column Null Count: 19\n",
      "\n",
      "\n",
      "Column Name: Total expenditure\n",
      "Column DataType: float64\n",
      "Column has null: True\n",
      "Column Null Count: 226\n",
      "\n",
      "\n",
      "Column Name: Diphtheria \n",
      "Column DataType: float64\n",
      "Column has null: True\n",
      "Column Null Count: 19\n",
      "\n",
      "\n",
      "Column Name:  HIV/AIDS\n",
      "Column DataType: float64\n",
      "Column has null: False\n",
      "\n",
      "\n",
      "Column Name: GDP\n",
      "Column DataType: float64\n",
      "Column has null: True\n",
      "Column Null Count: 448\n",
      "\n",
      "\n",
      "Column Name: Population\n",
      "Column DataType: float64\n",
      "Column has null: True\n",
      "Column Null Count: 652\n",
      "\n",
      "\n",
      "Column Name:  thinness  1-19 years\n",
      "Column DataType: float64\n",
      "Column has null: True\n",
      "Column Null Count: 34\n",
      "\n",
      "\n",
      "Column Name:  thinness 5-9 years\n",
      "Column DataType: float64\n",
      "Column has null: True\n",
      "Column Null Count: 34\n",
      "\n",
      "\n",
      "Column Name: Income composition of resources\n",
      "Column DataType: float64\n",
      "Column has null: True\n",
      "Column Null Count: 167\n",
      "\n",
      "\n",
      "Column Name: Schooling\n",
      "Column DataType: float64\n",
      "Column has null: True\n",
      "Column Null Count: 163\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    float64\n",
      " 1   diagnosis                569 non-null    int32  \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(31), int32(1)\n",
      "memory usage: 140.2 KB\n",
      "None\n",
      "\n",
      "Regression:\n",
      "\n",
      "KNN Regression Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>P-Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CV_5</th>\n",
       "      <td>0.2295</td>\n",
       "      <td>0.1129</td>\n",
       "      <td>0.3341</td>\n",
       "      <td>0.8873</td>\n",
       "      <td>1,375.1319</td>\n",
       "      <td>1,489.1971</td>\n",
       "      <td>[[0.6279697821386685, 5.5949994153848646e-06, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_10</th>\n",
       "      <td>0.2169</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.3179</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>1,546.2709</td>\n",
       "      <td>1,662.9273</td>\n",
       "      <td>[[0.6414373800908385, 4.346370641099101e-07, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_15</th>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.1031</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>0.8971</td>\n",
       "      <td>1,602.8807</td>\n",
       "      <td>1,720.3372</td>\n",
       "      <td>[[0.6337422971958243, 1.949069897124804e-07, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE    MSE   RMSE  R-Squared        AIC        BIC  \\\n",
       "CV_5  0.2295 0.1129 0.3341     0.8873 1,375.1319 1,489.1971   \n",
       "CV_10 0.2169 0.1034 0.3179     0.8968 1,546.2709 1,662.9273   \n",
       "CV_15 0.2165 0.1031 0.3161     0.8971 1,602.8807 1,720.3372   \n",
       "\n",
       "                                                P-Values  \n",
       "CV_5   [[0.6279697821386685, 5.5949994153848646e-06, ...  \n",
       "CV_10  [[0.6414373800908385, 4.346370641099101e-07, 0...  \n",
       "CV_15  [[0.6337422971958243, 1.949069897124804e-07, 0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average p-value for CV_CV_5: 0.21454547449546657\n",
      "Average p-value for CV_CV_10: 0.2083206156785833\n",
      "Average p-value for CV_CV_15: 0.2058086237877868\n",
      "\n",
      "OLS Regression Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>AIC</th>\n",
       "      <th>BIC</th>\n",
       "      <th>P-Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CV_5</th>\n",
       "      <td>0.3157</td>\n",
       "      <td>0.1689</td>\n",
       "      <td>0.4109</td>\n",
       "      <td>0.8289</td>\n",
       "      <td>1,375.1319</td>\n",
       "      <td>1,489.1971</td>\n",
       "      <td>0.2145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_10</th>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.4083</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>1,546.2709</td>\n",
       "      <td>1,662.9273</td>\n",
       "      <td>0.2083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_15</th>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>0.4074</td>\n",
       "      <td>0.8299</td>\n",
       "      <td>1,602.8807</td>\n",
       "      <td>1,720.3372</td>\n",
       "      <td>0.2058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE    MSE   RMSE  R-Squared        AIC        BIC  P-Values\n",
       "CV_5  0.3157 0.1689 0.4109     0.8289 1,375.1319 1,489.1971    0.2145\n",
       "CV_10 0.3140 0.1668 0.4083     0.8300 1,546.2709 1,662.9273    0.2083\n",
       "CV_15 0.3135 0.1666 0.4074     0.8299 1,602.8807 1,720.3372    0.2058"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_life_expectancy\n",
    "null_check(r_life_expectancy)\n",
    "print(c_cancer.info())\n",
    "clean_data(r_life_expectancy,[])\n",
    "r_life_expectancy = transform_data(r_life_expectancy)\n",
    "\n",
    "# Define the number of splits for cross-validation\n",
    "cv_splits = [5, 10, 15]\n",
    "\n",
    "print(\"\\nRegression:\")\n",
    "knn_metrics = KNNRegressionMetrics(r_life_expectancy, 'Life expectancy ', cv_splits)\n",
    "print(\"\\nKNN Regression Metrics:\")\n",
    "display(knn_metrics)\n",
    "# For KNN P-value Avg\n",
    "flattened_p_values = knn_metrics['P-Values'].apply(lambda x: [item for sublist in x for item in sublist])\n",
    "avg_p_values_by_cv = {}\n",
    "for cv_split, p_values in flattened_p_values.items():\n",
    "    avg_p_values_by_cv[cv_split] = np.mean(p_values)\n",
    "for cv_split, avg_p_value in avg_p_values_by_cv.items():\n",
    "    print(f\"Average p-value for CV_{cv_split}: {avg_p_value}\")\n",
    "\n",
    "ols_metrics = OLSRegressionMetrics(r_life_expectancy, 'Life expectancy ', cv_splits)\n",
    "print(\"\\nOLS Regression Metrics:\")\n",
    "display(ols_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab71dde1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
